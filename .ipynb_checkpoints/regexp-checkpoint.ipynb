{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search('abc', 'abcde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\" Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures\n",
    ".\t        Wildcard, matches any character\n",
    "^abc\t    Matches some pattern abc at the start of a string\n",
    "abc$\t    Matches some pattern abc at the end of a string\n",
    "[abc]\t    Matches one of a set of characters\n",
    "[^abc]      Matches anything but a set of characters\n",
    "[A-Z0-9]\tMatches one of a range of characters\n",
    "ed|ing|s\tMatches one of the specified strings (disjunction)\n",
    "*\t        Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\n",
    "+\t        One or more of previous item, e.g. a+, [a-z]+\n",
    "?\t        Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\n",
    "{n}\t        Exactly n repeats where n is a non-negative integer\n",
    "{n,}\t    At least n repeats\n",
    "{,n}\t    No more than n repeats\n",
    "{m,n}\t    At least m and no more than n repeats\n",
    "a(b|c)+\t    Parentheses that indicate the scope of the operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/EddieGHWon/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aa', 'aal', 'aalii', 'aam', 'aardvark', 'aardwolf', 'aba', 'abac', 'abaca']\n",
      "['abaissed', 'abandoned', 'abased', 'abashed', 'abatised', 'abed', 'aborted', 'abridged', 'abscessed', 'absconded']\n",
      "['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector', 'majestic', 'objectee', 'objector', 'rejecter', 'rejector']\n",
      "['gold', 'golf', 'hold', 'hole']\n",
      "['a', 'aa', 'ah', 'aha', 'h', 'ha', 'hah']\n",
      "['0.0085', '0.05', '0.1', '0.16', '0.2', '0.25', '0.28', '0.3', '0.4', '0.5']\n",
      "['C$', 'US$']\n",
      "['1614', '1637', '1787', '1901', '1903', '1917', '1925', '1929', '1933', '1934']\n",
      "['10-day', '10-lap', '10-year', '100-share', '12-point', '12-year', '14-hour', '15-day', '150-point', '190-point']\n",
      "['black-and-white', 'bread-and-butter', 'father-in-law', 'machine-gun-toting', 'savings-and-loan']\n",
      "['62%-owned', 'Absorbed', 'According', 'Adopting', 'Advanced', 'Advancing', 'Alfred', 'Allied', 'Annualized', 'Anything']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('treebank')\n",
    "\n",
    "wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()]\n",
    "print(wordlist[:10])\n",
    "\n",
    "result = [w for w in wordlist if re.search('ed$', w)][:10]\n",
    "print(result[:10])\n",
    "\n",
    "result = [w for w in wordlist if re.search('^..j..t..$', w)][:10]\n",
    "print(result[:10])\n",
    "\n",
    "result = [w for w in wordlist if re.search('^[ghi][mno][jlk][def]$', w)][:10]\n",
    "print(result[:10])\n",
    "\n",
    "result = [w for w in wordlist if re.search('^[ah]+$', w)][:10]\n",
    "print(result[:10])\n",
    "\n",
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "wordlist = [w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)]\n",
    "print(wordlist[:10])\n",
    "\n",
    "wordlist = [w for w in wsj if re.search('^[A-Z]+\\$$', w)]\n",
    "print(wordlist[:10])\n",
    "\n",
    "wordlist = [w for w in wsj if re.search('^[0-9]{4}$', w)]\n",
    "print(wordlist[:10])\n",
    "\n",
    "wordlist = [w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]\n",
    "print(wordlist[:10])\n",
    "\n",
    "wordlist = [w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]\n",
    "print(wordlist[:10])\n",
    "\n",
    "wordlist = [w for w in wsj if re.search('(ed|ing)$', w)]\n",
    "print(wordlist[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', 'e', 'a', 'i', 'a', 'i', 'i', 'i', 'e', 'i', 'a', 'i', 'o', 'i', 'o', 'u']\n",
      "['rc', 'fr', 'st', 'xp', 'ci']\n",
      "['supercalifragilisticexpialidocious']\n",
      "['sup', 'rcal', 'frag', 'lis', 'tic', 'xpial', 'doc']\n"
     ]
    }
   ],
   "source": [
    "word = 'supercalifragilisticexpialidocious'\n",
    "result = re.findall(r'[aeiou]', word)\n",
    "print(result)\n",
    "\n",
    "result = re.findall('[aeiou](..)[aeiou]', word)\n",
    "print(result)\n",
    "\n",
    "result = re.findall('[^aeiou].+[^aeiou]', word)\n",
    "print(result)\n",
    "\n",
    "result = re.findall('[^aeiou].+?[^aeiou]', word)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('io', 549),\n",
       " ('ea', 476),\n",
       " ('ie', 331),\n",
       " ('ou', 329),\n",
       " ('ai', 261),\n",
       " ('ia', 253),\n",
       " ('ee', 217),\n",
       " ('oo', 174),\n",
       " ('ua', 109),\n",
       " ('au', 106)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "fdist = nltk.FreqDist(vs for word in wsj for vs in re.findall(r'[aeiou]{2,}', word))\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package udhr to /Users/EddieGHWon/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unvrsl Dclrtn of Hmn Rghts Prmble Whrs rcgntn of the inhrnt dgnty and\n",
      "of the eql and inlnble rghts of all mmbrs of the hmn fmly is the fndtn\n",
      "of frdm , jstce and pce in the wrld , Whrs dsrgrd and cntmpt fr hmn\n",
      "rghts hve rsltd in brbrs acts whch hve outrgd the cnscnce of mnknd ,\n",
      "and the advnt of a wrld in whch hmn bngs shll enjy frdm of spch and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/udhr.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('udhr')\n",
    "\n",
    "regexp = r'^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'\n",
    "def compress(word):\n",
    "    pieces = re.findall(regexp, word)\n",
    "    return ''.join(pieces)\n",
    "\n",
    "english_udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "print(nltk.tokenwrap(compress(w) for w in english_udhr[:75]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package toolbox to\n",
      "[nltk_data]     /Users/EddieGHWon/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   e   i   o   u \n",
      "k 418 148  94 420 173 \n",
      "p  83  31 105  34  51 \n",
      "r 187  63  84  89  79 \n",
      "s   0   0 100   2   1 \n",
      "t  47   8   0 148  37 \n",
      "v  93  27 105  48  49 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/toolbox.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('toolbox')\n",
    "rotokas_words = nltk.corpus.toolbox.words('rotokas.dic')\n",
    "cvs = [cv for w in rotokas_words for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cfd = nltk.ConditionalFreqDist(cvs) # CFD works pairwise only\n",
    "cfd.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kaapo',\n",
       " 'kaapopato',\n",
       " 'kaipori',\n",
       " 'kaiporipie',\n",
       " 'kaiporivira',\n",
       " 'kapo',\n",
       " 'kapoa',\n",
       " 'kapokao',\n",
       " 'kapokapo',\n",
       " 'kapokapo',\n",
       " 'kapokapoa',\n",
       " 'kapokapoa',\n",
       " 'kapokapora',\n",
       " 'kapokapora',\n",
       " 'kapokaporo',\n",
       " 'kapokaporo',\n",
       " 'kapokari',\n",
       " 'kapokarito',\n",
       " 'kapokoa',\n",
       " 'kapoo',\n",
       " 'kapooto',\n",
       " 'kapoovira',\n",
       " 'kapopaa',\n",
       " 'kaporo',\n",
       " 'kaporo',\n",
       " 'kaporopa',\n",
       " 'kaporoto',\n",
       " 'kapoto',\n",
       " 'karokaropo',\n",
       " 'karopo',\n",
       " 'kepo',\n",
       " 'kepoi',\n",
       " 'keposi',\n",
       " 'kepoto']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_word_pairs = [(cv, w) for w in rotokas_words for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cv_index = nltk.Index(cv_word_pairs)\n",
    "cv_index['po']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
